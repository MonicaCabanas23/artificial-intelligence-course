{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 6: Clasificación Lineal\n",
    "\n",
    "En esta clase estudiaremos los problemas de clasificación lineal, particularmente LDA (Linear deiscriminant Analysis) y regresión Logística.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> \n",
    "    ¿Porqué no es bueno utilizar una regresión para solucionar un problema de clasificación?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> \n",
    "    Cuando estudiamos regresión vimos que una de las características de la regresión lineal es que la media de los errores es cero. Esto hace que la media y la varianza de los errores seán independientes, lo cual es optimo en ML. Sin embargo, si utilizamos regresión en un problema de clasificación, dado la naturaleza discreta de la(s) salida(s), la varianza en los datos de entrada va a producir que el valor medio del error y la varianza esten relacionadas, tal como se muestra en las siguientes imagenes:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/Regresion_Clas_1.png\" width=\"400\">\n",
    "<img src=\"img/Regresion_Clas_2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA), aproximación de Fisher\n",
    "\n",
    "Supongamos que tenemos un conjunto de datos $\\{(\\mathbf{x}^{(1)}, y^{(1)}), (\\mathbf{x}^{(2)}, y^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)})\\}$, donde $\\mathbf{x}^{(i)}\\in\\mathbb{R}^n$ y $y \\in\\{0,1\\}$. Sea $\\text{p}(\\mathbf{x}|y=0)$ y $\\text{p}(\\mathbf{x}|y=1)$ las distribuciones de probabilidad para los valores de $\\mathbf{x}$ que perteneces a la clase $y = 0$ y $y=1$, respectivamente. La idea detras del LDA es tratar de encontrar la dirección de un eje, de tal forma que al proyectar $\\mathbf{x}$ sobre este se maximiza la separación entre las medias de las distribuciones de probabilidad de las variables proyectadas, y al mismo tiempo se minimizan sus varianzas. En otras palabras lo que busca LDA es realizar una transformación lineal de los datos de entrada, tal que se maximice su disperción entre clases, y se minimice su disperción dentro de cada clase. La siguiente figura explica este proceso de forma grafica:\n",
    "![title](img/LDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se plantea este problema?\n",
    "\n",
    "Para solucionar este problema debemos plantear la función de costo.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> \n",
    "    ¿Cuál sería esa función de costo?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> \n",
    "    Esa función de costo se define de la siguiente forma:\n",
    "\n",
    "sea $\\hat{y} = \\theta_0+\\boldsymbol\\theta^T\\mathbf{x}$ la salida estimada de mi modelo de clasificación, teniendo como base esto, el valor medio de esta salida está dado por:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\boldsymbol\\mu_i=\\frac{1}{n_i}\\sum_{k\\in C_i}\\mathbf{x}^{(k)}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "donde $C_i$ es el conjunto de datos de entrada $\\mathbf{x}$ que pertenecen a la clase $i$, $\\mu_i$ es la media de estos elementos, y $n_i$ es el número de muestras que pertencen a esa clase. y la varianza está dada por:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\boldsymbol\\Sigma_i=\\frac{1}{(n_i-1)}\\sum_{k\\in C_i}(\\mathbf{x}^{(k)}-\\boldsymbol\\mu_k)(\\mathbf{x}^{(k)}-\\boldsymbol\\mu_k)^\\text{T}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "donde $\\text{T}$ es la transpuesta.\n",
    "\n",
    "De aquí se puede definir la media y la varianza de los valores predecidos de $y$, de forma que:\n",
    "\n",
    "sea $\\hat{y}= \\theta_0+\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}$, se tiene:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{E}[\\hat{y}|\\mathbf{x}\\in C_i] & = & \\theta_0 +\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\mu_i \\\\\n",
    "\\text{Var}[\\hat{y}|\\mathbf{x}\\in C_i] &=& \\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_i\\boldsymbol\\theta\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "De allí la función de costo, asuminedo dos clases, es:\n",
    "\n",
    "$$\\hat{\\boldsymbol\\theta} := \\max\\limits_\\boldsymbol\\theta \\frac{(\\boldsymbol\\mu_0^{\\text{T}}\\boldsymbol\\theta-\\boldsymbol\\mu_1^{\\text{T}}\\boldsymbol\\theta)^2}{\\left(n_0\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_0\\boldsymbol\\theta+n_1\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_1\\boldsymbol\\theta\\right)} = \\frac{\\left((\\boldsymbol\\mu_0^{\\text{T}}-\\boldsymbol\\mu_1^{\\text{T}})\\boldsymbol\\theta\\right)^2}{\\boldsymbol\\theta^{\\text{T}}\\left(n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1\\right)\\boldsymbol\\theta}$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> \n",
    "    ¿Cómo maximizar esa función?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> \n",
    "    sea $\\mathbf{m}^{\\text{T}}=\\boldsymbol\\mu_0^{\\text{T}}-\\boldsymbol\\mu_1^{\\text{T}}$ y $\\mathbf{S}=n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1$, el problema se reduce a:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{\\left(\\mathbf{m}^{\\text{T}}\\boldsymbol\\theta\\right)^2}{\\boldsymbol\\theta^{\\text{T}}\\mathbf{S}\\boldsymbol\\theta}.$$\n",
    "\n",
    "Cómo $\\mathbf{S}$ es una matrix simetrica, entonces $\\mathbf{S}= \\mathbf{R}^\\text{T}\\mathbf{R}$, con $\\mathbf{R}$ la raiz de $\\mathbf{S}$, y sea $\\mathbf{v} = \\mathbf{R}\\boldsymbol\\theta$, se tiene:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{\\left(\\mathbf{m}^{\\text{T}}\\mathbf{R}^{-1}\\mathbf{v}\\right)^2}{\\mathbf{v}^{\\text{T}}\\mathbf{v}}= \\frac{\\left(\\mathbf{m}^{\\text{T}}\\mathbf{R}^{-1}\\mathbf{v}\\right)^2}{||\\mathbf{v}||^2}=\\left(\\mathbf{m}^\\text{T}\\mathbf{R}^{-1}\\frac{\\mathbf{v}}{||\\mathbf{v}||}\\right)^2=\\left(\\left((\\mathbf{R}^{-1})^\\text{T}\\mathbf{m}\\right)^\\text{T}\\frac{\\mathbf{v}}{||\\mathbf{v}||}\\right)^2.$$\n",
    "\n",
    "se busca maximizar ese producto punto, el cual es máximo si los dos vectores estan en la misma dirección. Propongamos que $\\mathbf{v}= a (\\mathbf{R}^{-1})^\\text{T}\\mathbf{m}$, donde $a$ es una constante, es el vector que máximiza ese producto punto. Tomando de antes $\\mathbf{m} = \\boldsymbol\\mu_0-\\boldsymbol\\mu_1$, y $\\boldsymbol\\theta=\\mathbf{R}^{-1}\\mathbf{v}$ se tiene:\n",
    "\n",
    "$$ \\boldsymbol\\theta = a\\mathbf{R}^{-1}(\\mathbf{R^{-1}})^{\\text{T}}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1)=a(\\mathbf{R}^\\text{T}\\mathbf{R})^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1),$$\n",
    "\n",
    "lo cual se simplifica por:\n",
    "\n",
    "$$\\boldsymbol\\theta = a\\mathbf{S}^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1)=a\\left(n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1\\right)^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1),$$\n",
    "\n",
    "con $a$ una constante arbitraria que puede ser 1. De allí:\n",
    "$$\\theta_0 = \\text{E}[y-\\boldsymbol\\theta^\\text{T}\\mathbf{x}] = \\frac{1}{n}\\sum y^{(i)}-\\boldsymbol\\theta^\\text{T}\\mathbf{x}^{(i)}.$$\n",
    "\n",
    "De forma sencilla, lo que se esta haciendo es tomar el vector de la diferencia de ambas medias, y se rota por medio de la inversa de las covarianzas de los datos, i.e. donde mas varian los datos tiene el menor efecto en esta rotación.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Nota:</b> LDA considera que los datos en cada clase estan distribuidos de forma Normal, y que las matrices de covarianza de las distribuciones son iguales. Fisher no requiere asumir estás cosas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA a traves de Bayes\n",
    "\n",
    "Se puede llegar a LDA a traves de Bayes, sabiendo que:\n",
    "\n",
    "$$\\text{p}(y=1|\\mathbf{x})=\\frac{\\text{p}(\\mathbf{x}|y=1)\\text{p}(y=1)}{\\text{p}(\\mathbf{x})},$$\n",
    "\n",
    "donde $\\text{p}(\\mathbf{x}) = \\text{p}(\\mathbf{x}|y=1)\\text{p}(y=1)+\\text{p}(\\mathbf{x}|y=0)\\text{p}(y=0)$. En términos de probabilidades el likelihood (similaridad) es $\\text{p}(\\mathbf{x}|y=1)$, el prior es $\\text{p}(y=1)$ y la probabilidad marginal es $\\text{p}(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "\n",
    "La regresión logística es un metodo de clasificación, a pesar de que se conoce como regresión. Para la clasificación quisieramos que los valores de salida de nuestro modelo este acotado entre cero (0 -1) y uno. Para lograr esto, asumamos que nuestro modelo tiene la forma:\n",
    "\n",
    "$$h_{\\boldsymbol\\theta}(\\mathbf{x}) = g(\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}),$$\n",
    "\n",
    "donde $g(\\displaystyle\\mathbf{z})=\\frac{1}{1+e^{-\\mathbf{z}}}$ es una función sigmoidal o logística. Por lo tanto la forma del modelo es:\n",
    "\n",
    "$$h_{\\boldsymbol\\theta}(\\mathbf{x}) = \\frac{1}{1+e^{-\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}}}.$$\n",
    "\n",
    "La función logística luce como se muestra en la siguiente figura:\n",
    "\n",
    "<img src=\"img/logit.png\" width=\"400\">\n",
    "\n",
    "El problema se reduce a encontrar los valores de $\\boldsymbol\\theta$ que garantizan que tenga una buena clasificación. \n",
    "\n",
    "En el caso de un modelo de clasificación para dos clases, la salida de este modelo se puede interpretar como la probabilidad de que la salida sea $y=1$ cuando la entrada es $\\mathbf{x}$, i.e. $\\text{p}(y=1|\\mathbf{x};\\boldsymbol\\theta)$. Teniendo en cuenta esto, y debido a que las probabilidades de pertenecer a una clase o la otra deben sumar uno, se tiene que $\\text{p}(y=0|\\mathbf{x};\\boldsymbol\\theta) = 1-\\text{p}(y=1|\\mathbf{x};\\boldsymbol\\theta)$.\n",
    "\n",
    "Para terminar se puede entonces definir la salida de tal forma que:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\hat{y} =\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if} & h_{\\boldsymbol\\theta}(\\mathbf{x}) \\geq 0.5\\\\\n",
    "      0 & \\text{if} & h_{\\boldsymbol\\theta}(\\mathbf{x}) < 0.5\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limite de Desición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> \n",
    "    Considerando el problema de forma geométrica, ¿cuando la función logística será mayor a 0.5?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> La salida del modelo será 1, i.e. $g(\\mathbf{z}) \\geq 0.5$ cuando $\\boldsymbol\\theta^\\text{T}\\mathbf{x}\\geq 0$. Si graficamos en el espacio de características, el hyper-plano donde los ejes son las variables de entrada, la ecuación $\\boldsymbol\\theta^{\\text{T}}\\mathbf{x} = 0$, se obtiene lo que se conoce coómo el limite de desición (desición boundary), tal como muestra la siguiente figura:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/DesicionBoundary.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Este limite de decision separa el espacio de caracteristicas en dos regiones tal que si una entranda $\\mathbf{x}$ se encuentra en una de esta su salida será $y=0$ o $y=1$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b>  ¿Qué tipo de limite de desición forma el modelo $h_{\\boldsymbol\\theta}(\\mathbf{x}) = g([-1;1;1]^\\text{T}[1;x_1^2;x_2^2])$?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> El limite de desición estaría dado por $[−1;1;1]^\\text{T}[1;𝑥_1^2;𝑥_2^2]\\geq 0$, o en otras palabras por $x_1^2+x_2^2 \\geq 1$, como se muestra en la figura de abajo. Es decir que se pueden crear fronteras no lineales, de la misma forma que en el caso de la regresion lineal. Lo importante es que este elemnto del modelo sea lineal en los parámetros $\\boldsymbol\\theta$, pero se puede hacer tan complicado como se desee eligiendo transformaciones no lineales de los regresores. \n",
    "</div>\n",
    "\n",
    "<img src=\"img/NonlinearBound.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Nota:</b> EL limite de desición depende del modelo, no de los datos, los datos se utilizan solo para calcular los parámetros.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste del modelo\n",
    "\n",
    "Sea nuestro vector $\\mathbf{x}^{(i)} = [x_0^{(i)};x_1^{(i)};\\ldots;x_n^{(i)}]$, con $x_0^{(i)} = 1$, para todo $i$, y $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{n+1}$ y $y\\in\\{0,1\\}$. Dado el set de entrenamiento como se encuentran los parámetros $\\boldsymbol\\theta$.\n",
    "\n",
    "Definamos la función de costo para nuestra regresión:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\text{costo}(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)}),y^{(i)}),$$\n",
    "\n",
    "donde $$\\text{costo}(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)}),y^{(i)})= \\frac{1}{2}\\left(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)})-y^{(i)}\\right)^2.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> ¿Cuál es el problema de esta función de costo?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b>  esta función de costo, debido a la forma de $h$ es una función no convexa, por lo tanto gradiente descendiente puede que no converga al mínimo global. Siempre es deseable tener, en lo posible, funciones de costo convexas, por lo tanto, en este caso, hay que redefinirla.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La nueva función de costo para este problema es:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\text{costo}(h_\\boldsymbol\\theta(\\mathbf{x}),y) =\n",
    "    \\begin{cases}\n",
    "      -\\log(h_\\boldsymbol\\theta(\\mathbf{x})) & \\text{if} & y=1\\\\\n",
    "      -log(1-h_\\boldsymbol\\theta(\\mathbf{x})) & \\text{if} & y=0\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> ¿Cómo luce la función de costo de la regresión logistica?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b>  La función de costo luce como en la siguiente figura:\n",
    "</div>\n",
    "\n",
    "<img src=\"img/Costo_Logit.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Esta función de costo garantiza que si mi predicción es correcta $h_\\boldsymbol\\theta(\\mathbf{x}) = y$ entonces el costo es 0, si la predicción es incorrecta, el costo tiende al $\\infty$. Además esta función es convexa, lo cual facilita la aplicación de gradient descent.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta este nuevo costo, se obtiene que:\n",
    "\n",
    " $$ \\text{costo}(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}),y^{(i)}) = -y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))-(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})).$$\n",
    " \n",
    " De allí la función de costo para la regresión logística estará dada por:\n",
    " \n",
    " $$\\mathbf{J}(\\boldsymbol\\theta) = -\\frac{1}{m}\\left(\\sum_{i=1}^{m}y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))\\right).$$\n",
    " \n",
    "Lo único que queda por hacer es encontrar los parámetros $\\boldsymbol\\theta$ que minimizan esa función de costo. Para hacer esto se utiliza gradient descent.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> ¿Qué necesitamos para poder desarrollar el gradient desecent?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> Para implementar el algoritmo, necesitamos encontrar la derivada de la función de costo en función de los parámetros.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> ¿Cuanto da la derivada de la función de costo en función de los parámetros?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> La derivada tiene como resultado:\n",
    "\n",
    "$$\\frac{\\partial\\mathbf{J}(\\boldsymbol\\theta)}{\\partial\\theta_j} = \\frac{1}{m}\\sum_{i=1}^m\\left(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right)x_j^{(i)}$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, la regla de actualización de los pesos en gradient descent, par ala regresión logistica, esta dada por:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "      \\theta_n := \\theta_n-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_n^{(i)}\\\\\n",
    "   \\end{equation}$$\n",
    "   \n",
    "Donde $x_0^{(i)}= 1$ para todo $i$. aunque luce identico al gradiente descendiente para regresión lineal, no lo es, ya que la función $h_\\boldsymbol\\theta(\\mathbf{x})$ es diferente a la función de regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Nota 1:</b> La normalización de caracteristicas (regresores) también aplica para gradeinte descendiente cuando se usa la regresión logistica. De la misma forma que aplica en regresion lineal.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Nota 2:</b> Aparte de gradient descent existen otros algoritmos más sofisticados que permiten encontrar los parámetros que minimizan la función de costo. Generalmente ellos requieren una función para el cálculo del costo y de su derivada en función de los parámetros. Además, ellos son más rápidos y no requieren de sintonizar la taza de aprendizaje, pero son más complicados. Estos algoritmos no se estudiaran en el curso, hacen parte del curso de Optimización, (Conjugate gradient, BFGS, L-BGFS)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística Multiclase\n",
    "\n",
    "Si se tienen $p$ clases, se pueden entrenar $p$ clasificadores, utilizando regresión logistica, y al final se agregan las salidas de cada clasificador, de tal forma que la clase seleccionada sea aquella que tenga la mayor probabilidad (la mayor variable latente de salida del clasificador). Tal como se explica en la figura:\n",
    "\n",
    "<img src=\"img/onevsrest.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> ¿Qué sucede si no escojo al final la clase que de la mayor probabilidad, sino que escojo en función de si la probabilidad es mayor a 0.5?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> si se realiza de esta forma la asignación de la clase se puede crear una región de ambiguedad, tal como se muestra en la figura de abajo:\n",
    "\n",
    "</div>\n",
    "<img src=\"img/Ambiguedad.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matematicamente, la salida del clasificador está dada por: \n",
    "\n",
    "$$\\hat{y} = \\max\\limits_ih^{(i)}_\\boldsymbol\\theta(\\mathbf{x}),$$\n",
    "\n",
    "donde $h^{(i)}_\\boldsymbol\\theta(\\mathbf{x})$ es la salida del clasificador entrenado para la clase $i$.\n",
    "\n",
    "Otra estrategia es combinar las variables latentes (antes de aplicar la función logistica) a una función tipo softmax, aunque esto no es generalmente conocido como regresión logistica:\n",
    "\n",
    "$$\\sigma(\\mathbf{z})_j=\\frac{e^{z_j}}{\\sum_{k=1}^pe^{z_k}},$$\n",
    "\n",
    "donde $z_k=\\boldsymbol\\theta_k^\\text{T}\\mathbf{x}$, para $k=\\{1,\\ldots,p\\}$ y $\\mathbf{z}=[z_1,\\ldots,z_p]^\\text{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización en Regresión Logistica\n",
    "\n",
    "La regresión logistica puede tambien llegar a ser sobre-ajustada.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Pregunta:</b> ¿Qué significa que la regresión logistica pueda ser sobre-ajustada?¿Cómo luce un clasificador sobreajustado?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Solución:</b> Un clasificador sobreajustado genera limites de desición extremadamente complicados, no suaves, que no son capaces de generalizar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar el sobreajuste en la regresión logistica, podemos usar el mismo criterio que en regresión, disminuir el número de  regresores, o utilizar regularización, tipo LASSO, Tickhonov, etc... De está forma la nueva función de costo será:\n",
    "\n",
    " $$\\mathbf{J}(\\boldsymbol\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+\\frac{\\gamma}{2m}\\sum_{j=1}^n\\theta_j^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La actualización en gradiente descendiente sería:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "\\begin{split}\n",
    "    \\theta_0&:=& \\theta_0-\\alpha\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_0^{(i)}\\right]\\\\\n",
    "\\theta_j &:=& \\theta_n-\\alpha\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_j^{(i)}+\\frac{\\gamma}{m}\\theta_j\\right]\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "con $j={1,\\ldots,n}$. Donde el modelo $h_\\boldsymbol\\theta(\\mathbf{x})$ es la función logistica y $x_0^{(i)}=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
